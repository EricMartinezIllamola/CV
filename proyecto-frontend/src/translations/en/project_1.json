{
    "h1": "Clustering",
    "t1": "Machine Learning",
    "p1": "Machine Learning (ML) se considera una subcategoría de la Inteligencia Artificial (AI). Frecuentemente, se relaciona con cierta capacidad de predicción de la máquina, y aunque eso es cierto, probablemente sería más acertado definir ML como el proceso mediante el cual  una máquina es capaz de replicar la capacidad humana de aprender. Pero, ¿qué significa que una máquina sea capaz de aprender? \n \nPensemos en el proceso de aprendizaje que se puede dar en un ser humano, concretamente en el caso de un niño. Por ejemplo, le queremos enseñar a diferenciar entre los perros y los gatos, para ello le mostramos la foto de un perro y le decimos 'Esto es un perro', le mostramos la foto de un gato y la decimos 'Esto es un gato', y así con varias fotos de distintos perros y distintos gatos. Tras este proceso de aprendizaje, le mostramos al niño la foto de un perro y le preguntamos '¿Qué animal aparece en la imagen? ¿Un perro o un gato?', y esperamos que el niño responda correctamente. ¡El niño ha aprendido lo qué son los perros y los gatos! Pero, si le mostramos la foto de una jirafa, el niño no será capaz de decirnos qué animal aparece en la foto, pues aún no lo ha aprendido.",
    "t2": "Text Mining, Topic Model",
    "p2": "En el caso de ML el proceso de aprendizaje es algo parecido. En este caso utilizaremos Text Mining, concretamente lo que se conoce como Topic Model. Topic Model es un proceso de aprendizaje automático que enseña a la máquina a diferenciar entre textos de diferentes temáticas, basándose en la frecuencia de aparición de las palabras (el número de veces que aparece una palabra en un determinado texto). \n \n¿Cómo sería en nuestro caso el proceso de aprendizaje? Le mostramos a la máquina las frecuencias de aparición de las palabras de un texto (la palabra A aparece X veces, la palabra B aparece Y veces…) y le decimos 'Este texto trata sobre la temática 1', le mostramos  las frecuencias de otro texto y le decimos 'Este texto trata sobre la temática 2' y así con varios textos. Tras este proceso de aprendizaje (o entrenamiento), le mostramos las frecuencias de un nuevo texto y esperamos que la máquina sea capaz de decirnos si pertenece a la temática 1 o a la temática 2. Para realizar ese proceso de aprendizaje utilizaremos el algoritmo de aprendizaje automático K-Nearest Neighbors (K-NN), como más adelante veremos.",
    "a1": {
        "p": "Empecemos por cargar e inspeccionar los datos (data_reuter.txt). Se trata de un conjunto de documentos sobre distintas temáticas relacionadas con inversiones financieras y fondos de inversión: acquire, crude, earn, grain, interest, money-fx, ship y trade. 8 temáticas distintas, pero bastante parecidas entre ellas.",
        "c": "#Definimos directorio de trabajo \n \nsetwd('ruta') \n \n#Cargamos los paquetes necesarios \n \nlibrary(tm) \n library(plyr) \nlibrary(class) \nlibrary(caret) \n\n#Leemos los datos \n \noptions(stringsAsFactors = FALSE) \ndata <- read.table('data_reuter.txt', header=FALSE, sep='\\t')"
    },
    "i1": "Tabla del número de documentos por temática. \n \nknitr::kable(table(data$V1), 'simple', col.names = c('Tematica', 'Nº Doc'), align = c('l', 'r'))",
    "i2": "Gráfico del número de documentos por temática. \n \nqplot(data$V1,xlab='Tematica', main = 'Frecuencias')+ coord_flip()",
    "a2": {
        "p": "De las 8 temáticas, vamos a seleccionar 2: acq y earn, por ser las temáticas con más documentos. El siguiente paso será 'limpiar el texto' y quedarnos solo con aquellas palabras con significado, es decir, realizar la creación y acondicionamiento del corpus para cada temática. Acondicionamiento significa: convertir el texto a minúsculas, eliminar números, eliminar signos de puntuación, eliminar espacios en blanco innecesarios, eliminar palabras sin significado propio y sustituir palabras derivadas por palabras raíz.",
        "c": "#Seleccionamos las 2 temáticas (acq y earn) \n \ndata2<-data[which(data$V1 %in% c('acq','earn')),] \n \n#Creación y acondicionamiento del corpus de la temática acq. \n \ndata_acq<-data2[(data2$V1=='acq'),] \nsource <- VectorSource(data_acq$V2) \ncorpus1 <- Corpus(source) \ncorpus1 <- tm_map(corpus1, content_transformer(tolower)) \ncorpus1 <- tm_map(corpus1, removeNumbers) \ncorpus1 <- tm_map(corpus1, removePunctuation) \ncorpus1 <- tm_map(corpus1, stripWhitespace) \nv_stopwords <- c(stopwords('english'),c('dont','didnt','arent','cant','one','also','said')) \ncorpus1 <- tm_map(corpus1, removeWords, v_stopwords) \ncorpus1 <- tm_map(corpus1, removePunctuation) \ncorpus1 <- tm_map(corpus1, stemDocument, language='english') \n \n#Creación y acondicionamiento del corpus de la temática earn. \n \ndata_earn<-data2[(data2$V1=='earn'),] \nsource <- VectorSource(data_earn$V2) \ncorpus2 <- Corpus(source) \ncorpus2 <- tm_map(corpus2, content_transformer(tolower)) \ncorpus2 <- tm_map(corpus2, removeNumbers) \ncorpus2 <- tm_map(corpus2, removePunctuation) \ncorpus2 <- tm_map(corpus2, stripWhitespace) \nv_stopwords <- c(stopwords('english'),c('dont','didnt','arent','cant','one','also','said')) \ncorpus2 <- tm_map(corpus2, removeWords, v_stopwords) \ncorpus2 <- tm_map(corpus2, removePunctuation) \ncorpus2 <- tm_map(corpus2, stemDocument, language='english')"
    },
    "a3": {
        "p": "A partir del corpus generamos la matriz de términos (TDM-Terms Data Matrix) para cada temática. La TDM es una matriz en la que las filas son palabras y las columnas son documentos, por lo que en cada celda aparece la frecuencia de aparición de esa palabra en ese documento. Tras generar la TDM, hemos aplicado  'removeSparseTerms' con un valor de 0,8 (dispersión máxima). \n \nEn ambas matrices de términos se ha fijado una dispersión máxima del 80% (0.80). ¿Qué significa eso? \n \nnº de documentos*(1-0,8)= X \n \nacq: 1596*(0.2)= 319,2 \n \nearn: 2840*(0.2)= 568 \n \nSolo se tienen en cuenta los términos que aparezcan como mínimo en X documentos (X=319 en el caso de 'acq' y X=568 en el caso de 'earn'). \n \nUna vez eliminados los términos que aparecen en menos de X documentos, nos sale una matriz de términos con un cierto nivel de dispersión (sparsity). \n \nSparsity(acq)= 63%; Sparsity(earn)= 61% \n \nLa sparsity nos indica la cantidad de valores igual a cero (sparse entries), respecto al número total de valores que tiene la matriz (núm. de términos * núm. de documentos). \n \nSparsity=(sparse entries/(núm. de terminos * núm. de documentos))*100 \n \nSparsity(acq)= (20173/(201596))*100= 63,2% \n \nSparsity(earn)= (38001/(222840))*100= 60,8% \n \nSparsity(acq) > Sparsity(earn) implica que un % más elevado de los valores de la matriz acq son ceros (63.2%), en comparación con la matriz earn (60.8%). Un cero significa que ese término no aparece en ese documento.",
        "c": "#Generación de la matriz de términos (TDM-Terms Data Matrix) para la temática acq. \n \nmat_acq <- TermDocumentMatrix(corpus1) \nmat_acq<- removeSparseTerms(mat_acq,  0.80) \nmat_acq<-list(name='acq',mat=mat_acq) \n \n#Generación de la matriz de términos (TDM-Terms Data Matrix) para la temática earn. \n \nmat_earn <- TermDocumentMatrix(corpus2) \nmat_earn<- removeSparseTerms(mat_earn,  0.80) \nmat_earn<-list(name='earn',mat=mat_earn) \n \n#Juntamos ambas matrices \n \nmat<-list(mat_acq, mat_earn)"
    },
    "i3": "Inspeccionamos la TDM de la temática 'acq' que hemos creado. \n \ninspect(mat[[1]]$mat)",
    "i4": "Inspeccionamos la TDM de la temática 'earn' que hemos creado. \n \ninspect(mat[[2]]$mat)",
    "a4": {
        "p": "Por ahora dejamos a un lado las TDM que hemos creado. Lo que ahora nos interesa es crear unas matrices con las frecuencias de aparición de las palabras agregadas por temática. Es decir, estas nuevas matrices nos indicarán el número de veces que aparece cada palabra en los documentos de una determinada temática (en lugar de en un determinado documento). Por ejemplo, la palabra 'share' aparece 2164 veces en los documentos de la temática 'acq'. Creamos una matriz de frecuencias agregadas para acq (d_acq), una para earn (d_earn) y una para el conjunto de las 2 temáticas (fdata). Estas nuevas matrices las utilizaremos para visualizar los datos y entenderlos mejor.",
        "c": "#Transformación para agregar las frecuencias (temática acq) \n \nmmat_acq <- as.matrix(mat[[1]]$mat) \n v_acq <- sort(rowSums(mmat_acq), decreasing=TRUE) \nd_acq <- data.frame(word=names(v_acq), freq=v_acq) \nd_acq[,3]<-'acq' \n \n#Transformación para agregar las frecuencias (temática earn) \n \nmmat_earn <- as.matrix(mat[[2]]$mat) \nv_earn <- sort(rowSums(mmat_earn), decreasing=TRUE) \nd_earn <- data.frame(word=names(v_earn), freq=v_earn) \nd_earn[,3]<-'earn' \n \n#Juntamos las 2 matrices y cambiamos el nombre de las columnas \n \nfdata<-rbind(d_acq,d_earn) \ncolnames(fdata)<-c('Palabra', 'Frecuencia', 'Tematica') \ncolnames(d_acq)<-c('Palabra', 'Frecuencia', 'Tematica') \ncolnames(d_earn)<-c('Palabra', 'Frecuencia', 'Tematica')"
    },
    "i5": "Visualizamos, en una tabla, los primeros registros de la matriz de frecuencias agregadas 'fdata', simplemente para hacernos una idea de qué hay dentro. \n \nknitr::kable(head(fdata), 'simple', align = 'l')",
    "i6": "Representamos los datos de 'fdata' en forma de un gráfico horizontal de barras apiladas, mostrando solo las palabras con una frecuencia mayor a 400. \n \nLas barras de un solo color implican que esos términos solo aparecen en documentos de una temática. Por ejemplo, 'year' muestra una barra de un único color (azul), por lo que el término 'year' solo aparece en los documentos de temática 'earn'. Los términos que solo aparecen en documentos de una temática son particularmente interesantes para nuestro objetivo. \n \nLas barras de dos colores implican que esos términos aparecen tanto en documentos de la temática 'acq' cómo en documentos de la temática 'earn'. \n \nggplot(subset(fdata,Frecuencia>400),aes(Frecuencia,Palabra,fill=Tematica))+geom_bar(stat='identity',position=position_stack())+theme(axis.text.x=element_text(angle=45, hjust=1))",
    "i7": "Las nubes de palabras (word cloud) representan la misma información que el gráfico de barras apiladas, pero de forma más visual: al aumentar la frecuencia agregada de una palabra, aumenta el tamaño de esa palabra (en la nube de palabras). \n \nWord cloud de los términos de la temática 'acq'. \n \nsd_acq<-subset(d_acq, Frecuencia>400) \nwordcloud(sd_acq$Palabra, d_acq$Frecuencia,min.freq=400,scale=c(3,.5),random.color=FALSE, colors=rainbow(3))",
    "i8": "Word cloud de los términos de la temática 'earn'. \n \nsd_earn<-subset(d_earn, Frecuencia>400) \nwordcloud(sd_earn$Palabra, d_earn$Frecuencia,min.freq=400,scale=c(4,.5),random.color=FALSE, colors=rainbow(3))",
    "i9": "Word cloud de los términos de ambas temáticas, cada temática de un color distinto: rojo='acq', azul='earn'. \n \nsfdata<-subset(fdata, Frecuencia>400) \nwordcloud(sfdata$Palabra, fdata$Frecuencia,min.freq=400,scale=c(3.5,.5),random.color=FALSE,ordered.colors=TRUE,colors=rainbow(2)[factor(fdata$Tematica)])",
    "a5": {
        "p": "Una vez hemos visualizado las frecuencias agregadas y nos hemos hecho una idea del contenido de nuestros textos, es momento de empezar a aplicar el algoritmo de aprendizaje automático K-NN. Así que, dejamos a un lado 'fdata' y continuamos con la matriz 'mat' (la TDM). Pero necesitamos crear un data frame apto para K-NN, lo cual implica hacer 2 cosas. Por un lado, las filas deben contener los documentos y las columnas las palabras (justo al contrario de la TDM que tenemos). Por otro lado, debemos 'guardar por separado' las frecuencias de las temáticas (la variable objetivo).",
        "c": "#Creación de un data.frame apto para K-NN \n \n#Acq \n \ns.mat_acq <- t(data.matrix(mat[[1]]$mat)) \ns.df_acq <- as.data.frame(s.mat_acq, stringsAsFactors = FALSE) \nTema <- rep(mat[[1]]$name, nrow(s.df_acq)) \ns.df_acq<-cbind(s.df_acq,Tema) \n \n#Earn \n \ns.mat_earn <- t(data.matrix(mat[[2]]$mat)) \ns.df_earn <- as.data.frame(s.mat_earn, stringsAsFactors = FALSE) \nTema <- rep(mat[[2]]$name, nrow(s.df_earn)) \ns.df_earn<-cbind(s.df_earn,Tema) \n \n#Conectar las 2 matrices \n \npila <-rbind.fill(s.df_acq, s.df_earn) \npila[is.na(pila)] <- 0 "
    },
    "a6": {
        "p": "Ahora dividimos nuestro juego de datos en 2: uno de entrenamiento ('entrena.idx') que contendrá el 70% (X documentos) y otro para las pruebas ('test.idx') que contendrá el 30% (X documentos).  La división del juego de datos es aleatoria, pero al haber plantado una semilla ('set.seed(111)'), esa aleatoriedad es repetible. En cualquier caso, utilizaremos 'entrena.idx' para realizar el proceso de aprendizaje y 'test.idx' para comprobar la eficacia del aprendizaje (el nivel de acierto del modelo).",
        "c": "set.seed(111) \nentrena.idx <- sample(nrow(pila), ceiling(nrow(pila) * 0.7)) \ntest.idx <- (1:nrow(pila))[-entrena.idx] \ntema <- pila[, 'Tema'] \npila.nl <- pila[, !colnames(pila) %in% 'Tema'] "
    },
    "a7": {
        "p": "Todo listo. Aplicamos la función K-NN del paquete class. Le pasamos 3 parámetros: la matriz de frecuencias de entrenamiento ('pila.nl[entrena.idx, ]'), la matriz de frecuencias de test ('pila.nl[test.idx, ]') y las temáticas de los documentos de entrenamiento ('tema[entrena.idx]').No le pasamos las temáticas de los documentos de test, pues es justamente lo que el modelo tiene que predecir.",
        "c": "#Función knn paquete class \n \nknn.pred <- knn(pila.nl[entrena.idx, ], pila.nl[test.idx, ], tema[entrena.idx])"
    },
    "p3": "En este punto parece interesante explicar en qué consiste el algoritmo K-NN. K-Nearest Neighbors o K vecinos más cercanos, tal y como su nombre indica, clasifica los documentos basándose en los k vecinos más cercanos (documentos más parecidos al documento que se quiere clasificar). \n \nPongamos el ejemplo de k=1: para clasificar un documento A, se busca el documento con la distancia más pequeña respecto al documento A, es decir, el documento más similar al documento A según el modelo (documento B). Si el documento B pertenece a la temática 'acq', el documento A se clasificará dentro de la temática 'acq'. Si el documento B pertenece a la temática 'earn', el documento A se clasificará dentro de la temática 'earn'. \n \nEn este caso, usar valores de k pares, puede llegar a suponer un problema. Pensemos en el caso de k=2: para clasificar un documento A, se busca los 2 documentos con la distancia más pequeña respeto al documento A, los documentos B y C. Si tanto el documento B como el documento C pertenecen a la temática 'acq', el documento A se clasificará dentro de la temática 'acq'. Si tanto el documento B como el documento C pertenecen a la temática 'earn', el documento A se clasificará dentro de la temática 'earn'. Pero si el documento B y el documento C pertenecen a distintas temáticas (uno pertenece a 'acq' y el otro pertenece a 'earn'), la función knn() no será capaz de clasificar el documento A (o lo hará al azar). \n \nNosotros utilizaremos k=1 para la función knn() del paquete class, que es el valor por defecto.Recordar que, cuando hablamos de 'documentos más parecidos' o 'vecinos más cercanos', se mide a partir de la distancia entre estos documentos (similarmente a cómo se calcula la distancia entre dos puntos). Por defecto, la función knn() utiliza la distancia euclídea. En nuestro caso hablamos de distancia entre documentos, donde las variables son las frecuencias de los términos. Pero existen otros tipos de distancias, cómo la distancia estadística o la distancia de Mahalanobis.",
    "i10": "Obtenemos 'knn.pred', que contiene las predicciones de los XX documentos de test ('acq' o 'earn'). Visualizamos los primeros 6 registros a modo de ejemplo. En este caso, la predicción nos dice que los 6 primeros documentos pertenecen a la temática 'acq'. \n \nhead(knn.pred)",
    "a8": {
        "p": "Ya tenemos una predicción, pero, ¿cómo saber si esas predicciones son correctas? ¿Qué nivel de acierto tienen? Nos hace falta realizar la validación de los resultados, es decir, comparar los valores obtenidos en la predicción ('knn.pred') con los valores reales ('tema[test.idx]').",
        "c": "#Validación knn - class \n \nconf.mat <- table('Predicción' = knn.pred,'Real' = tema[test.idx])"
    },
    "i11": "Visualizamos la matriz de confusión. Obtenemos 4 datos: 470 documentos se han predicho como 'acq' y en realidad eran 'acq', 15 se han predicho como 'acq' y en realidad eran 'earn', 20 se han predicho como 'earn' y en realidad eran 'acq' y 825 se han predicho como 'earn' y en realidad eran 'earn'. \n \nconf.mat",
    "a9": {
        "p": "Estos 4 datos pueden parecer poca cosa, pero en realidad nos aportan mucha información. A partir de ellos podemos calcular varios valores estadísticos que nos pueden resultar de ayuda para validar los resultados. En este caso, hemos creado 2 variables: 'Sensitivity' y 'Specificity'. \n \n'Sensitivity' = (470 / (470+20)) * 100 = 95.92% \nDe 490 documentos que pertenecen a la temática 'acq', se han detectado 470, un 95.92%. \n \n'Specificity' = (825 / (825+15)) * 100 = 98.21% \nDe 840 documentos que pertenecen a la temática 'earn', se han detectado 825, un 98.21%.",
        "c": "Sensitivity <- (conf.mat[1,1]/(conf.mat[1,1]+conf.mat[2,1]))*100 \n \nSpecificity <- (conf.mat[2,2]/(conf.mat[1,2]+conf.mat[2,2]))*100"
    },
    "i12": "Visualizamos 'Sensitivity '. \n \nSensitivity",
    "i13": "Visualizamos 'Specificity  '. \n \nSpecificity",
    "p4": "Ahora vamos a aplicar K-NN, pero esta vez con la función train() del paquete caret. ¿Qué diferencia existe respecto a la función knn() del paquete class en nuestro caso? \n \nLa función knn() utiliza el juego de datos de entrenamiento (70%) para desarrollar un modelo, con un valor de k fijado a priori (k=1). Justo después de aplicar el entrenamiento, no nos da ninguna información referente a la calidad ni al nivel de acierto del modelo, para ello debemos validar el modelo con los datos de pruebas (30%).\n\nCon la función train() ocurre algo similar, pero con varias diferencias. La función train() no tiene un valor de k fijo, sino que k tiene un rango de valores (k=1, k=2 y k=3). Dentro del propio entrenamiento, la función train() realiza procesos de remuestreo (método bootstrap): obtiene múltiples muestras del juego de datos de entrenamiento (70%) para ir repitiendo múltiples veces el proceso de entrenamiento (25 repeticiones). En esas 25 repeticiones 'entrena' con los 3 posibles valores de k y nos informa de la accuracy asociada a cada uno de esos valores. Digamos que la función train() crea diferentes modelos, mide su nivel de acierto (accuracy) y finalmente escoge el mejor modelo (el modelo con el nivel de acierto más elevado).\n\nAccuracy es igual al número de aciertos dividido entre el número de documentos totales. Se calcula a partir de la matriz de confusión, en el caso de la función knn() sería:\n\naccuracy = ((825+470) / (825+470+15+20)) = 0.9737",
    "a10": {
        "p": "Aplicamos la función train(), le pasamos la matriz de frecuencias de entrenamiento ('pila.nl[entrena.idx, ]') y las temáticas de los documentos de entrenamiento ('tema[entrena.idx]'). Por otro lado, le decimos que aplique el método knn y que lo aplique con k entre 1 y 3.",
        "c": "#Función train paquete caret \n \ndat_train<-cbind(pila.nl[entrena.idx, ],tema[entrena.idx]) \nknnGrid <-  expand.grid(k = c(1:3)) \nknn.caret <- train(`tema[entrena.idx]`~., data=dat_train,method = 'knn',tuneGrid = knnGrid)"
    },
    "i14": "Visualizamos 'knn.caret'. Observamos que ha escogido k=1 basándose en el nivel de accuracy. \n \nknn.caret",
    "a11": {
        "p": "Realizamos la validación de la función train() del paquete caret. Le pasamos los datos de pruebas ('test.idx').",
        "c": "#Validación train- caret \n \ndat_test<-cbind(pila.nl[test.idx, ],tema[test.idx]) \npreds_knn<-predict(knn.caret, dat_test)"
    },
    "i15": "Vemos que la matriz de confusión del paquete caret nos da mucha más información. Aparte de la matriz de confusión en sí, nos aparecen varios valores estadísticos. En el caso de la función knn() hemos tenido que calcular sensitivity, specificity y accuracy 'a mano'. No vamos a comentar todos estos valores, pero se calculan a partir de la matriz de confusión. Los resultados son muy parecidos a los de la función knn(), pero con 4 aciertos más (35 fallos con la función knn(), 31 fallos con la función train()). \n \nconfusionMatrix(preds_knn,as.factor(dat_test$`tema[test.idx]`))"
}