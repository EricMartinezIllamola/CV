{
    "h1": "Clustering",
    "p1": "En este proyecto vamos a utilizar el algoritmo de aprendizaje automático K-means para la formación de clusters (grupos o perfiles de países).",
    "t1": "Aprendizaje no supervisado: K-means",
    "p2": "K-means es un algoritmo de aprendizaje automático no supervisado. ¿Qué significa eso? En el aprendizaje no supervisado no le enseñamos a la máquina a partir de ejemplos ya resueltos, sino que más bien es la máquina la que aprende por sí misma. \n \nPor ejemplo, en el proyecto anterior (text mining) hemos utilizado un algoritmo de aprendizaje supervisado (K-NN). Le mostrábamos un documento a la máquina y le decíamos a qué temática pertenece (proceso de aprendizaje o entrenamiento). Luego le mostrábamos un nuevo documento con la intención de que la máquina nos indique a qué temática pertenece (dentro de las temáticas que le hemos enseñado). \n \nCon el aprendizaje no supervisado no existe tal proceso de entrenamiento o aprendizaje 'dirigido'. Por ejemplo, en este proyecto le pasaremos a la máquina un conjunto de datos sobre 167 países y esperaremos que los agrupe en X clusters. Todo esto puede parecer extraño, pero se entenderá mejor a medida que vayamos avanzando.",
    "p3": "Empecemos. Nuestros datos de partida ('Country-data.csv') recogen información sociodemográfica y económica de 167 países, en particular se muestran las siguientes variables: \n \ncountry: Nombre del país \n \nchild_mort: Mortalidad infantil, de niños menores de 5 años, por cada 1000 nacimientos \n \nexports: Exportación de bienes y servicios per cápita. En forma del porcentaje del PIB per cápita \n \nhealth: Total de gasto en sanidad per cápita. En forma del porcentaje del PIB per cápita \n \nimports: Importación de bienes y servicios per cápita. En forma del porcentaje del PIB per cápita \n \nincome: Ingresos netos por persona \n \ninflation: Inflación, crecimiento anual del PIB total \n \nlife_expec: Esperanza de vida, de un recién nacido, suponiendo que los patrones de mortalidad actuales se mantienen igual en el futuro \n \ntotal_fer: Número de nacimientos por mujer, suponiendo que los porcentajes de fertilidad por edades se mantienen igual en el futuro \n \ngdpp: PIB per cápita. Calculado como el PIB total dividido entre la población total",
    "a1": {
        "p": "Empezamos definiendo el directorio de trabajo y cargando los datos.",
        "c": "#Definimos directorio de trabajo y cargamos los datos \n \nsetwd(“ruta”) \ncountries = read.csv('Country-data.csv', na.string = c('', 'NA'))"
    },
    "i1": "Visualizamos los primeros 6 registros de 'countries' a modo de ejemplo. \n \nhead(countries)",
    "p4": "El objetivo del análisis es separar los países en diferentes grupos en base a la salud de sus ciudadanos (child_mort y life_expec), a su riqueza (gdpp y income) y al nivel de gasto en salud (health). ¿Qué clase de países existen? ¿Todos los países ricos han logrado obtener un buen nivel de salud? ¿Existen países con un elevado nivel de salud aun disponiendo de un nivel de riqueza limitada? ¿Un elevado gasto en salud (health) implica siempre una mejora en los indicadores de la salud de los ciudadanos (child_mort y life_expec)?",
    "a2": {
        "p": "Para hacer nuestro análisis, solo utilizaremos 5 de las variables: 'child_mort', 'life_expec', 'health', 'gdpp', 'income'. Y lo llamamos 'clus'.",
        "c": "clus<-countries[,c('child_mort','life_expec','health','gdpp','income')]"
    },
    "i2": "Visualizamos los primeros 6 registros de 'clus_title' a modo de ejemplo, 'clus_title' es igual que 'clus', pero añadiendo el nombre de los países (para visualizar los datos). \n \nclus_title<-countries[,c('country', 'child_mort','life_expec','health','gdpp','income')] \n \nknitr::kable(head(clus_title), 'simple')",
    "i3": "Visualizar los primeros registros nos ayuda a hacernos una idea de la estructura de nuestros datos de origen, pero no nos aporta demasiado. \n \nAhora visualizamos, para cada columna, los principales estadísticos: valor mínimo, máximo, media… \n \nsummary(clus)",
    "i4": "Representamos, en un gráfico de dispersión, 'life_expec' vs 'health'. \n \nplot(countries[c('life_expec','health')], xlab='Esperanza de vida', ylab='Inversión en salud (%)'') title(main='Nube de puntos A1', col.main='blue', font.main=1)",
    "i5": "Representamos, en un gráfico de dispersión, 'life_expec' vs 'gdpp'. \n \nplot(countries[c('life_expec','gdpp')], xlab='Esperanza de vida', ylab='GDDP') title(main='Nube de puntos B1', col.main='blue', font.main=1)",
    "i6": "Representamos, en un gráfico de dispersión, 'health' vs 'gdpp'. \n \nplot(countries[c('health','gdpp')], xlab='Inversión en salud (%)', ylab='GDPP') title(main='Nube de puntos C1', col.main='blue', font.main=1)",
    "a3": {
        "p": "Ahora ya nos hemos hecho una idea general de nuestros datos. Antes de aplicar el algoritmo k-means tenemos que normalizar los datos. ¿Qué significa normalizar los datos? Ahora mismo nuestras 5 variables tienen una varianza (o rango de valores) distintos, ya que miden diferentes características de los países (algunas hasta están en diferentes unidades). \n \nPongamos un ejemplo, si la inversión en salud aumenta del 7% al 14%, aumenta 7 puntos, del mismo modo que si la esperanza de vida aumenta desde los 70 años a los 77. Pero el aumento no es precisamente comparable, pues en el primer caso es un aumento del 100%, mientras que en el segundo es un aumento del 10%. \n \nNormalizar las variables nos permite ponerlas todas en un mismo rango de valores, lo que nos permite compararlas de forma más adecuada.",
        "c": "#Normalizamos las variables \n \nclus_norm<-clus \nclus_norm[,c('child_mort')] <- (clus$child_mort-mean(clus$child_mort))/sd(clus$child_mort) \nclus_norm[,c('life_expec')] <- (clus$life_expec-mean(clus$life_expec))/sd(clus$life_expec) \nclus_norm[,c('health')] <- (clus$health-mean(clus$health))/sd(clus$health) \nclus_norm[,c('gdpp')] <- (clus$gdpp-mean(clus$gdpp))/sd(clus$gdpp) \nclus_norm[,c('income')] <- (clus$income-mean(clus$income))/sd(clus$income)"
    },
    "p5": "Una vez las variables normalizadas, ya podemos aplicar el algoritmo k-means para realizar el clustering (clasificar los países en diferentes clusters o grupos, en base a las 5 variables que hemos elegido), esto se consigue comparando a los diferentes países entre sí. \n \nPara cada país se calcula la distancia respecto al resto de países (lo parecidos o diferentes que son dos países, en base a comparar los valores de nuestras 5 variables normalizadas). Los países más parecidos entre sí se clasifican en un mismo grupo. \n \nLa mayor problemática, o dificultad, de esta técnica es elegir el número de clusters. ¿Cuál es el número adecuado? Aunque existen diferentes métodos para elegir el número de clusters, realmente no existe una única respuesta válida, no existe un único número de clusters adecuado. \n \nEn cualquier caso, para seleccionar el número de clusters existen métodos objetivos que se basan en la optimización de un criterio de ajuste. \n \nLos principales criterios de ajustes para k-means son: la suma de cuadrados entre grupos (betweenss) y la suma de cuadrados dentro de los grupos (withins). \n \nLa segmentación se considera óptima cuando los países son lo más homogéneos (parecidos) respecto a los otros países de su grupo y son lo más heterogéneos (diferentes) respecto a los países de los otros grupos. \n \nEs decir, se busca maximizar el valor de betweenss y minimizar el valor de withins, siempre que se obtenga un número de grupos razonable para nuestro análisis.",
    "a4": {
        "p": "Calculamos la suma de cuadrados entre grupos (betweenss) en función del número de grupos (entre 1 y 10).",
        "c": "#Calculamos 'betweenss' \n \nset.seed(123) \nbss <- kmeans(clus_norm,centers=1)$betweenss \nfor (i in 2:10) bss[i] <- kmeans(clus_norm,centers=i)$betweenss"
    },
    "i7": "Visualizamos la suma de cuadrados entre grupos (betweenss) en función del número de grupos. \n \nplot(1:10, bss, type='l', xlab='Número de grupos',ylab='Sumas de cuadrados entre grupos')",
    "p6": "Basándonos en el gráfico de betweens vs nº de cluster (k), parece haber 3 valores de k que destacan sobre el resto: k=3, k=5 y k=7. Betweens nos indica el grado de diferencia entre los clusters: un valor de betweens más elevado significa que los clusters son más diferentes entre sí. Si solo nos interesase maximizar el valor de betweens, escogeríamos k=10 (o un valor de k aún mayor), pero eso significaría segmentar los datos en un número de clusters muy elevado. Se trata de intentar llegar a un equilibrio entre maximizar el valor de betweens, pero sin aumentar el número de clusters de forma desproporcionada. Por lo general sería útil identificar los máximos relativos, pero en este caso solo existe un máximo (k=10). ¿Por qué destacamos entonces k=3, k=5 y k=7? La pendiente justo antes de estos puntos es mayor que la pendiente justo después de ellos.",
    "a5": {
        "p": "Ahora sí, ya podemos aplicar el algoritmo k-means. Fijamos el número de clusters en 5.",
        "c": "#K-means \n \nclus_kmeans=clus \nNumCluster=5 \nset.seed(123) \nModelo=kmeans(clus_norm,NumCluster) \nclus_kmeans$clusterKmeans= Modelo$cluster"
    },
    "i8": "Visualizamos, para cada uno de los 5 grupos que hemos creado, la media de las diferentes variables. \n \nknitr::kable(aggregate(.~clusterKmeans,FUN=mean, data=clus_kmeans), 'simple')",
    "i9": "Visualizamos, para cada uno de los 5 grupos que hemos creado, el número de países clasificados en ese grupo. \n \nknitr::kable(table(clus_kmeans$clusterKmeans), 'simple')",
    "p7": "El cluster 1 agrupa a países con elevados niveles de riqueza (gdpp y income), con elevados niveles de salud (child_mort y life_expec), y que su nivel de gasto en salud es muy elevado (health). \n \nEl cluster 5 es similar al cluster 1: países con elevados niveles de riqueza y elevados niveles de salud. Pero presenta una diferencia clara: su nivel de gasto en salud es mucho más bajo. ¿Más eficientes? \n \nEl cluster 2 agrupa a países con niveles de riqueza media (ni muy ricos ni muy pobres), pero con unos niveles de salud bastante elevados (aunque no tanto como los cluster 1 y 5). \n \nEl cluster 3 agrupa a los países con niveles de riqueza y de salud más bajos. \n \nEl cluster 4 agrupa a países con niveles de riqueza bastante bajos, pero con niveles de salud medios (bastante mejores que los países del cluster 3).",
    "i10": "Representamos, en un gráfico de dispersión, 'life_expec' vs 'health'. \n \nPaleta de colores = cluster 1: negro, cluster 2: rojo, cluster 3: verde, cluster 4: azul y cluster 5: cyan. \n \nplot(clus_kmeans[c('life_expec','health')], xlab='Esperanza de vida', ylab='Inversión en salud (%)'',col=clus_kmeans$clusterKmeans) title(main='Nube de puntos A2', col.main='blue', font.main=1)",
    "i11": "Representamos, en un gráfico de dispersión, 'life_expec' vs 'gdpp'. \n \nPaleta de colores = cluster 1: negro, cluster 2: rojo, cluster 3: verde, cluster 4: azul y cluster 5: cyan. \n \nplot(clus_kmeans[c('life_expec','gdpp')], xlab='Esperanza de vida', ylab='GDDP',col=clus_kmeans$clusterKmeans) title(main='Nube de puntos B2', col.main='blue', font.main=1)",
    "i12": "Representamos, en un gráfico de dispersión, 'health' vs 'gdpp'. \n \nPaleta de colores = cluster 1: negro, cluster 2: rojo, cluster 3: verde, cluster 4: azul y cluster 5: cyan. \n \nplot(clus_kmeans[c('health','gdpp')], xlab='Inversión en salud (%)'', ylab='GDPP',col=clus_kmeans$clusterKmeans) title(main='Nube de puntos C2', col.main='blue', font.main=1)",
    "p8": "Ahora vamos a intentar entender mejor cómo funciona el clustering, viendo las características de los clusters a medida que se aumenta el valor de k (número de clusters), desde k=2 hasta k=5. \n \nAl pasar de k=2 a k=3, ¿se mantiene un cluster igual y el otro se divide en dos? ¿O los clusters de k=2 no tienen ninguna relación con los clusters de k=3? \n \nAl pasar de 2 a 3 clusters, de 3 a 4 clusters y de 4 a 5 clusters, no se mantiene ningún cluster igual. \n \nPor ejemplo, comparemos el número de elementos que se clasifican dentro del cluster nº 1 en los diferentes modelos: 39 para k=2, 31 para k=3, 25 para k=4 y 22 para k=5. Vemos como va variando poco a poco. Algo parecido ocurre con el resto de clusters. \n \nTambién podemos comparar la media de life_expec dentro del cluster nº1 en los diferentes modelos: 79.73 para k=2, 80.49 para k=3, 80.49 para k=4 y 80.87 para k=5. En este caso vemos como el cluster nº1 tiene una característica común en todos los modelos: se caracteriza por tener una life_expec (esperanza de vida) muy elevada. De hecho, el valor de life_expec se mantiene bastante constante. \n \nAlguien podría pensar que es simplemente una casualidad, pero lo mismo ocurre con el resto de clusters: aunque no se mantienen iguales, sí que mantienen ciertas características esenciales (no cambian de golpe, más bien se van “refinando”). \n \n¿Cuál es el valor de k adecuado? Al ir incrementando el valor de k, cada vez tenemos más clusters, por lo que cada vez tenemos más información: tener más grupos implica que podemos distinguir mejor entre los diferentes tipos de países. Por ejemplo, en k=2, solo somos capaces de distinguir entre países ricos y con elevados niveles de salud por un lado y países pobres y con malos niveles de salud por el otro. A medida que vamos aumentando el valor de k, cada vez somos capaces de ver más matices. \n \nEn k=5, obtenemos un nuevo cluster (nº5), en el cúal solo están incluidos 6 países. Ese cluster es muy parecido al cluster nº1, pero su principal diferencia es que tiene un nivel de health (gasto en salud) mucho más reducido. Eso sería un ejemplo de nuevos matices que se obtienen al aumentar el valor de k. \n \nAumentar el valor de k aporta nuevos matices y nueva información. La pregunta sería, ¿esa nueva información es relevante para nosotros? ¿Esa nueva información es útil para lograr nuestros objetivos? En este caso, la nueva información que nos proporciona el modelo de k=5, sí parece útil para nosotros. Por lo menos dentro del rango de valores que hemos analizado, k=5 continúa pareciendo la mejor opción.",
    "a6": {
        "p": "Aplicamos el algoritmo k-means fijando el número de clusters en 2.",
        "c": "#K=2 \n \nclus_kmeans=clus \nNumCluster=2 \nset.seed(123) \nModelo=kmeans(clus_norm,NumCluster) \nclus_kmeans$clusterKmeans= Modelo$cluster"
    },
    "i13": "Visualizamos, para cada uno de los 2 grupos que hemos creado, la media de las diferentes variables. \n \nknitr::kable(aggregate(.~clusterKmeans,FUN=mean, data=clus_kmeans), 'simple')",
    "i14": "Visualizamos, para cada uno de los 2 grupos que hemos creado, el número de países clasificados en ese grupo. \n \nknitr::kable(table(clus_kmeans$clusterKmeans), 'simple')",
    "a7": {
        "p": "Aplicamos el algoritmo k-means fijando el número de clusters en 3.",
        "c": "#K=3 \n \nclus_kmeans=clus \nNumCluster=3 \nset.seed(123) \nModelo=kmeans(clus_norm,NumCluster) \nclus_kmeans$clusterKmeans= Modelo$cluster"
    },
    "i15": "Visualizamos, para cada uno de los 3 grupos que hemos creado, la media de las diferentes variables. \n \nknitr::kable(aggregate(.~clusterKmeans,FUN=mean, data=clus_kmeans), 'simple')",
    "i16": "Visualizamos, para cada uno de los 3 grupos que hemos creado, el número de países clasificados en ese grupo. \n \nknitr::kable(table(clus_kmeans$clusterKmeans), 'simple')",
    "a8": {
        "p": "Aplicamos el algoritmo k-means fijando el número de clusters en 4.",
        "c": "#K=4 \n \nclus_kmeans=clus \nNumCluster=4 \nset.seed(123) \nModelo=kmeans(clus_norm,NumCluster) \nclus_kmeans$clusterKmeans= Modelo$cluster"
    },
    "i17": "Visualizamos, para cada uno de los 4 grupos que hemos creado, la media de las diferentes variables. \n \nknitr::kable(aggregate(.~clusterKmeans,FUN=mean, data=clus_kmeans), 'simple')",
    "i18": "Visualizamos, para cada uno de los 4 grupos que hemos creado, el número de países clasificados en ese grupo. \n \nknitr::kable(table(clus_kmeans$clusterKmeans), 'simple')",
    "a9": {
        "p": "Aplicamos el algoritmo k-means fijando el número de clusters en 5.",
        "c": "#K=5 \n \nclus_kmeans=clus \nNumCluster=5 \nset.seed(123) \nModelo=kmeans(clus_norm,NumCluster) \nclus_kmeans$clusterKmeans= Modelo$cluster"
    },
    "i19": "Visualizamos, para cada uno de los 5 grupos que hemos creado, la media de las diferentes variables. \n \nknitr::kable(aggregate(.~clusterKmeans,FUN=mean, data=clus_kmeans), 'simple')",
    "i20": "Visualizamos, para cada uno de los 5 grupos que hemos creado, el número de países clasificados en ese grupo. \n \nknitr::kable(table(clus_kmeans$clusterKmeans), 'simple')",
    "a10": {
        "p": "Silhouette",
        "c": "library(cluster) \nsilhouette_score <- function(k){ \n km <- kmeans(clus_norm, centers = k, nstart=25) \n ss <- silhouette(km$cluster, dist(clus_norm)) \n mean(ss[, 3]) \n} \nk <- 2:10 \navg_sil <- sapply(k, silhouette_score)"
    },
    "i21": "plot(k, type='b', avg_sil, xlab='Number of clusters', ylab='Average Silhouette Scores', frame=FALSE)"
}