{
    "h1": "Text Mining",
    "t1": "Machine Learning",
    "p1": "Machine Learning (ML) es considera una subcategoria de la Intel·ligència Artificial (AI). Sovint, es relaciona amb certa capacitat de predicció de la màquina, i encara que això és veritat, probablement seria més encertat definir ML com el procés a partir del qual una màquina és capaç de replicar la capacitat humana d'aprendre. Però, ¿que significa que una màquina sigui capaç d'aprendre? \n \nPensem en el procés d'aprenentatge que es pot donar en un ésser humà, concretament en el cas d'un nen. Per exemple, li volem ensenyar al nen a diferenciar entre els gossos i els gats, per aconseguir-ho li ensenyem la foto d'un gos i li diem 'Això és un gos', li ensenyem la foto d'un gat i li diem 'Això és un gat', i així amb varies fotos de diferents gossos i diferents gats. Un cop realitzat aquest procés d'aprenentatge, li ensenyem al nen la foto d'un gos i li preguntem '¿Quin animal apareix a la foto? ¿Un gos o un gat?'', i esperem que el nen respongui correctament. El nen ha après el que són els gossos i els gats, és capaç de distingir-los! Però, si li ensenyem la foto d'una girafa, el nen no serà capaç de dir-nos quin animal apareix a la foto, dons encara no ha après què és una girafa.",
    "t2": "Text Mining, Topic Model",
    "p2": "En el cas de ML el procés d'aprenentatge és bastant similar. En el nostre cas utilitzarem Text Mining, concretament el que es coneix com a Topic Model. Topic Model és un procés d'aprenentatge automàtic que ensenya a la màquina a diferenciar entre textos de diferents temàtiques, a partir de la freqüència d'aparició de les paraules (el número de vegades que apareix una paraula en un determinat text). \n \n¿Com seria en el nostre cas el procés d'aprenentatge? Li mostrem a la màquina les freqüències d'aparició de les paraules d'un text (la paraula A apareix X vegades, la paraula B apareix Y vegades) i li diem 'Aquest text tracta sobre la temàtica 1', li mostrem les freqüències d'un altre text i li diem 'Aquest text tracta sobre la temàtica 2' i així amb diversos textos. Un cop realitzat aquest procés d'aprenentatge (o d'entrenament), li mostrem les freqüències d'un nou text i esperem que la màquina sigui capaç de dir-nos si pertany a la temàtica 1 o a la temàtica 2. Per dur a terme aquest procés d'aprenentatge utilitzarem l'algoritme d'aprenentatge automàtic K-Nearest Neighbors (K-NN), tal com veurem més endavant.",
    "a1": {
        "p": "Comencem per carregar i inspeccionar les dades (data_reuter.txt). Es tracta d'un conjunt de documents sobre diferents temàtiques relacionades amb inversions financeres i fons d'inversió: acquire, crude, earn, grain, interest, money-fx, ship i trade. 8 temàtiques diferents, però bastant semblants entre elles.",
        "c": "#Definim el directori de treball \n \nsetwd(“ruta”) \n \n#Carregem els packages necessaris \n \nlibrary(tm) \n library(plyr) \nlibrary(class) \nlibrary(caret) \n\n#Llegim les dades \n \noptions(stringsAsFactors = FALSE) \ndata <- read.table('data_reuter.txt', header=FALSE, sep='\\t') "
    },
    "i1": "Taula del nombre de documents per temàtica. \n \nknitr::kable(table(data$V1), 'simple', col.names = c('Tematica', 'Nº Doc'), align = c('l', 'r'))",
    "i2": "Gràfic del nombre de documents per temàtica. \n \nqplot(data$V1,xlab=’Tematica’, main = ‘Frecuencias’)+ coord_flip()",
    "a2": {
        "p": "De les 8 temàtiques, seleccionem 2: acq i earn, al ser les temàtiques amb més documents. El següent pas serà ‘netejar els textos’ i quedar-nos només amb les paraules amb significat propi, és a dir, realitzar la creació i acondicionament del corpus per cada temàtica. Acondicionament significa: convertir el text a minúscules, eliminar números, eliminar signes de puntuació, eliminar espais en blanc innecessaris, eliminar paraules sense significat propi i substituir paraules derivades per la seva arrel.",
        "c": "#Seleccionem les 2 temàtiques (acq i earn) \n \ndata2<-data[which(data$V1 %in% c(‘acq’,’earn’)),] \n \n#Creació i acondicionament del corpus de la temàtica acq. \n \ndata_acq<-data2[(data2$V1==’acq’),] \nsource <- VectorSource(data_acq$V2) \ncorpus1 <- Corpus(source) \ncorpus1 <- tm_map(corpus1, content_transformer(tolower)) \ncorpus1 <- tm_map(corpus1, removeNumbers) \ncorpus1 <- tm_map(corpus1, removePunctuation) \ncorpus1 <- tm_map(corpus1, stripWhitespace) \nv_stopwords <- c(stopwords(‘english’),c(‘dont’,’didnt’,’arent’,’cant’,’one’,’also’,’said’)) \ncorpus1 <- tm_map(corpus1, removeWords, v_stopwords) \ncorpus1 <- tm_map(corpus1, removePunctuation) \ncorpus1 <- tm_map(corpus1, stemDocument, language=’english’) \n \n#Creació i acondicionament del corpus de la temàtica earn. \n \ndata_earn<-data2[(data2$V1==’earn’),] \nsource <- VectorSource(data_earn$V2) \ncorpus2 <- Corpus(source) \ncorpus2 <- tm_map(corpus2, content_transformer(tolower)) \ncorpus2 <- tm_map(corpus2, removeNumbers) \ncorpus2 <- tm_map(corpus2, removePunctuation) \ncorpus2 <- tm_map(corpus2, stripWhitespace) \nv_stopwords <- c(stopwords(‘english’),c(‘dont’,’didnt’,’arent’,’cant’,’one’,’also’,’said’)) \ncorpus2 <- tm_map(corpus2, removeWords, v_stopwords) \ncorpus2 <- tm_map(corpus2, removePunctuation) \ncorpus2 <- tm_map(corpus2, stemDocument, language=’english’)"
    },
    "a3": {
        "p": "A partir del corpus generamos la matriz de términos (TDM-Terms Data Matrix) para cada temática. La TDM es una matriz en la que las filas son palabras y las columnas son documentos, por lo que en cada celda aparece la frecuencia de aparición de esa palabra en ese documento. Tras generar la TDM, hemos aplicado  'removeSparseTerms' con un valor de 0,8 (dispersión máxima). \n \nEn ambas matrices de términos se ha fijado una dispersión máxima del 80% (0.80). ¿Qué significa eso? \n \nnº de documentos*(1-0,8)= X \n \nacq: 1596*(0.2)= 319,2 \n \nearn: 2840*(0.2)= 568 \n \nSolo se tienen en cuenta los términos que aparezcan como mínimo en X documentos (X=319 en el caso de 'acq' y X=568 en el caso de 'earn'). \n \nUna vez eliminados los términos que aparecen en menos de X documentos, nos sale una matriz de términos con un cierto nivel de dispersión (sparsity). \n \nSparsity(acq)= 63%; Sparsity(earn)= 61% \n \nLa sparsity nos indica la cantidad de valores igual a cero (sparse entries), respecto al número total de valores que tiene la matriz (núm. de términos * núm. de documentos). \n \nSparsity=(sparse entries/(núm. de terminos * núm. de documentos))*100 \n \nSparsity(acq)= (20173/(201596))*100= 63,2% \n \nSparsity(earn)= (38001/(222840))*100= 60,8% \n \nSparsity(acq) > Sparsity(earn) implica que un % más elevado de los valores de la matriz acq son ceros (63.2%), en comparación con la matriz earn (60.8%). Un cero significa que ese término no aparece en ese documento.",
        "c": "#Generació de la matriu de termes (TDM-Terms Data Matrix) de la temàtica acq. \n \nmat_acq <- TermDocumentMatrix(corpus1) \nmat_acq<- removeSparseTerms(mat_acq,  0.80) \nmat_acq<-list(name=’acq’,mat=mat_acq) \n \n#Generació de la matriu de termes (TDM-Terms Data Matrix) de la temàtica earn. \n \nmat_earn <- TermDocumentMatrix(corpus2) \nmat_earn<- removeSparseTerms(mat_earn,  0.80) \nmat_earn<-list(name=’earn’,mat=mat_earn) \n \n#Unim les dues matrius \n \nmat<-list(mat_acq, mat_earn)"
    },
    "i3": "Inspeccionem la TDM de la temàtica ‘acq’ que hem creat. \n \ninspect(mat[[1]]$mat)",
    "i4": "Inspeccionem la TDM de la temàtica ‘earn’ que hem creat. \n \ninspect(mat[[2]]$mat)",
    "a4": {
        "p": "Per ara deixem aparcades les TDM que hem creat. El que ara ens interessa és crear unes matrius amb les freqüències d'aparició de les paraules agregades per temàtica. És a dir, aquestes noves matrius ens indicaran el nombre de vegades que apareix cada paraula en els documents d'una determinada temàtica (a ves d'en un determinat document). Per exemple, la paraula ‘share’ apareix 2164 vegades en els documents de la temàtica ‘acq’. Creem una matriu de freqüències agregades per acq (d_acq), una per earn (d_earn) i una pel conjunt de les 2 temàtiques (fdata). Aquestes noves matrius les utilitzarem per visualitzar les dades i entendre-les millor.",
        "c": "#Transformació per agregar les freqüències (temàtica acq) \n \nmmat_acq <- as.matrix(mat[[1]]$mat) \nv_acq <- sort(rowSums(mmat_acq), decreasing=TRUE) \nd_acq <- data.frame(word=names(v_acq), freq=v_acq) \nd_acq[,3]<-'acq' \n \n#Transformació per agregar les freqüències (temàtica earn) \n \nmmat_earn <- as.matrix(mat[[2]]$mat) \nv_earn <- sort(rowSums(mmat_earn), decreasing=TRUE) \nd_earn <- data.frame(word=names(v_earn), freq=v_earn) \nd_earn[,3]<-'earn' \n \n#Unim les 2 matrius i canviem el nom de les columnes \n \nfdata<-rbind(d_acq,d_earn) \ncolnames(fdata)<-c('Palabra', 'Frecuencia', 'Tematica') \ncolnames(d_acq)<-c('Palabra', 'Frecuencia', 'Tematica') \ncolnames(d_earn)<-c('Palabra', 'Frecuencia', 'Tematica')"
    },
    "i5": "Visualitzem, en una taula, els primers registres de la matriu de freqüències agregades 'fdata', simplement per fer-nos una idea de l'estructura interna de la matriu que acabem de crear. \n \nknitr::kable(head(fdata), 'simple', align = 'l')",
    "i6": "Representem les dades de 'fdata' en forma d'un gràfic horitzontal de barres apilades, mostrant només les paraules amb una freqüència major a 400. \n \nggplot(subset(fdata, Frecuencia>400), aes(Frecuencia, Palabra, fill=Tematica))+geom_bar(stat='identity', position=position_stack())+theme(axis.text.x=element_text(angle=45, hjust=1))",
    "p3": "Les barres d'un sol color impliquen que aquests termes només apareixen en documents d'una temàtica. Per exemple, 'year' té una barra d'un sol color (blau), per tant, el terme 'year' només apareix en els documents de la temàtica 'earn'. Els termes que apareixen en documents d'una sola temàtica són particularment interessants pel nostre objectiu. \n \nLes barres de dos colors impliquen que aquests termes apareixen tant en els documents de la temàtica 'acq' com en els documents de la temàtica 'earn'.",
    "i7": "Els núvols de paraules (word cloud) representen la mateixa informació que el gràfic de barres apilades, però de forma més visual: a l'augmentar la freqüència agregada d'una paraula, augmenta la grandària d'aquesta paraula (en el núvol de paraules). \n \nWord cloud dels termes de la temàtica 'acq'.",
    "i8": "Word cloud dels termes de la temàtica 'earn'. \n\nsd_earn<-subset(d_earn, Frecuencia>400) \nwordcloud(sd_earn$Palabra, d_earn$Frecuencia, min.freq=400, scale=c(4,.5), random.color=FALSE, colors=rainbow(3))",
    "i9": "Word cloud dels termes de les dues temàtiques, cada temàtica d’un color diferent: vermell='acq', blau='earn'. \n\nsfdata<-subset(fdata, Frecuencia>400) \nwordcloud(sfdata$Palabra, fdata$Frecuencia, min.freq=400, scale=c(3.5,.5), random.color=FALSE, ordered.colors=TRUE, colors=rainbow(2)[factor(fdata$Tematica)])",
    "a5": {
        "p": "Un cop hem visualitzat les freqüències agregades i ens hem fet una idea del contingut dels nostres textos, és moment de començar a aplicar l'algoritme d'aprenentatge automàtic K-NN. Així que, de moment ens oblidem de 'fdata' i a partir d'aquest punt continuem amb la matriu 'mat' (la TDM). Tenim la TDM, però necessitem crear un data frame apte per aplicar a K-NN, lo qual implica dues coses. Primer, les files han de representar els documents i les columnes a les paraules (just al contrari de la TDM que tenim). Segon, hem de 'guardar per separat' les freqüències de les temàtiques (la variable objectiu).",
        "c": "#Creació d’un data.frame apte per K-NN \n \n#Acq \n \ns.mat_acq <- t(data.matrix(mat[[1]]$mat)) \ns.df_acq <- as.data.frame(s.mat_acq, stringsAsFactors = FALSE) \nTema <- rep(mat[[1]]$name, nrow(s.df_acq)) \ns.df_acq<-cbind(s.df_acq,Tema) \n \n#Earn \n \ns.mat_earn <- t(data.matrix(mat[[2]]$mat)) \ns.df_earn <- as.data.frame(s.mat_earn, stringsAsFactors = FALSE) \nTema <- rep(mat[[2]]$name, nrow(s.df_earn)) \ns.df_earn<-cbind(s.df_earn,Tema) \n \n#Connectar les 2 matrius \n \npila <-rbind.fill(s.df_acq, s.df_earn) \npila[is.na(pila)] <- 0"
    },
    "a6": {
        "p": "Ara dividim el nostre joc de dades en 2: una primera part destinada a l'entrenament ('entrena.idx') que contindrà el 70% (X documents) i una segona part per realitzar les proves ('test.idx') que contindrà el 30% (X documents). La divisió de les dades és aleatòria, però a l'haver plantat una llavor (set.seed(111)), aquesta aleatorietat és repetible. En qualsevol cas, utilitzarem 'entrena.idx' per dur a terme el procés d'aprenentatge i 'test.idx' per comprovar l'eficàcia de l'aprenentatge (el nivell d'encert del model).",
        "c": "set.seed(111) \nentrena.idx <- sample(nrow(pila), ceiling(nrow(pila) * 0.7)) \ntest.idx <- (1:nrow(pila))[-entrena.idx] \ntema <- pila[, 'Tema'] \npila.nl <- pila[, !colnames(pila) %in% 'Tema']"
    },
    "a7": {
        "p": "Ja ho tenim tot preparat. Apliquem la funció K-NN del paquet class. Li passem 3 paràmetres: la matriu de freqüències d'entrenament ('pila.nl[entrena.idx, ]'), la matriu de freqüències de test ('pila.nl[test.idx, ]') i les temàtiques dels documents d'entrenament ('tema[entrena.idx]'). No li passem les temàtiques dels documents de test, ja que justament és allò que el model ha de predir.",
        "c": "#Función knn paquete class \n \nknn.pred <- knn(pila.nl[entrena.idx, ], pila.nl[test.idx, ], tema[entrena.idx])"
    },
    "p4": "En aquest punt sembla interessant explicar en què consisteix l'algoritme K-NN. K-Nearest Neighbors o K veïns més propers, tal com ens indica el seu nom, classifica els documents basant-se en els K veïns més propers (els documents més semblants al document que es pretén classificar). \n \nPosem l'exemple de k=1: per classificar un document A, es busca el document amb la distància més petita respecte al document A, és a dir, el document més similar al document A segons el model: el document B. Si el document B pertany a la temàtica 'acq', el document A es classificarà dintre de la temàtica 'acq'. Si el document B pertany a la temàtica 'earn', el document A es classificarà dintre de la temàtica 'earn'. \n \nEn aquest cas, utilitzar valors de k parells pot suposar un problema. Pensem en el cas de k=2: per classificar un document A, es busca els 2 documents amb la distància més petita respecte al document A: els documents B i C. Si tant el document B com el document C pertanyen a la temàtica 'acq', el document A es classificarà dintre de la temàtica 'acq'. Si tant el document B com el document C pertanyen a la temàtica 'earn', el document A es classificarà dintre de la temàtica 'earn'. Però si el document B i el document C pertanyen a temàtiques diferents (un a 'aqc' i l'altre a 'earn'), la funció knn() no serà capaç de classificar el document A (o ho farà a l'atzar). \n \nNosaltres utilitzarem k=1 en la funció knn() del paquet class, que és el valor per defecte. Cal recordar que quan parlem 'dels documents més similars' o 'dels veïns més propers', ens referim a la distància entre aquests documents (similarment a com es calcula la distància entre dos punts). Per defecte, la funció knn() fa servir la distància euclídea. En el nostre cas parlem de distància entre documents, on les variables són les freqüències dels termes. En qualsevol cas, a part de la distància euclídea, també existeixen altre tipus de distàncies, com la distància estadística o la distància de Mahalanobis.",
    "i10": "Obtenim 'knn.pred', que conté les prediccions dels XX documents de test (¿'acq' o 'earn'?). Visualitzem els primers 6 registres com a exemple. En aquest cas, la predicció ens diu que els 6 primers documents pertanyen a la temàtica 'acq'. \n \nhead(knn.pred)",
    "a8": {
        "p": "Ara ja tenim una predicció, però, com saber si aquestes prediccions són correctes? Quin nivell d'encert té el model? Ens fa falta dur a terme la validació dels resultats, és a dir, comparar els valors obtinguts en la predicció ('knn.pred') amb els valors reals ('tema[test.idx]').",
        "c": "#Validació knn - class \n \nconf.mat <- table('Predicción' = knn.pred,'Real' = tema[test.idx])"
    },
    "i11": "Visualitzem la matriu de confusió. Obtenim 4 dades: 470 documents s'han predit com 'acq' i en realitat eren 'acq', 15 s'han predit com 'acq' i en realitat eren 'earn', 20 s'han predit com 'earn' i en realitat eren 'acq' i 825 s'han predit com 'earn' i en realitat eren 'earn'. \n \nconf.mat",
    "a9": {
        "p": "Aquestes 4 dades poden semblar poca cosa, però en realitat ens aporten molta informació. A partir d'aquestes dades podem calcular diversos valors estadístics que ens poden resultar de molta ajuda a l'hora de validar els resultats. En aquest cas, n'hem creat 2: 'Sensitivity' i 'Specificity'. \n \n'Sensitivity' = (470 / (470+20)) * 100 = 95.92% \nDe 490 documents que pertanyen a la temàtica 'acq', se n'han detectat 470, un 95.92%. \n \n'Specificity' = (825 / (825+15)) * 100 = 98.21% \nDe 840 documents que pertanyen a la temàtica 'earn', se n'han detectat 825, un 98.21%.",
        "c": "Sensitivity <- (conf.mat[1,1]/(conf.mat[1,1]+conf.mat[2,1]))*100 \n \nSpecificity <- (conf.mat[2,2]/(conf.mat[1,2]+conf.mat[2,2]))*100"
    },
    "i12": "Visualitzem 'Sensitivity '. \n \nSensitivity",
    "i13": "Visualitzem 'Specificity  '. \n \nSpecificity",
    "p5": "Ara tornarem a aplicar K-NN, però aquest cop amb la funció train() del paquet caret. Quina diferència existeix respecte a la funció knn() del paquet class que hem aplicat abans? \n \nLa funció knn() utilitza el joc de dades d'entrenament (70%) per desenvolupar un model, amb un valor de k fixat a priori (k=1). Just després d'aplicar el procés d'entrenament, no ens dona cap mena d'informació referent a la qualitat ni al nivell d'encert del model, per obtenir aquesta informació cal validar el model amb les dades de proves (test). \n \nAmb la funció train() passa alguna cosa similar, però amb varies diferències. La funció train() no té un valor de k fix, sinó que k té un interval de valors (k=1, k=2 i k=3). En el mateix procés d'entrenament, la funció train() duu a terme processos de remostreig (mètode bootstrap): obté múltiples mostres del joc de dades d'entrenament (70%) per tal d'anar repetint múltiples vegades el procés d'entrenament (25 repeticions). En aquestes 25 repeticions 'entrena' amb els 3 possibles valores de k i ens informa de l'accuracy associada a cada un d'aquests valors. Diguem que la funció train() crea diferents models, mesura el seu nivell d'encert (accuracy) i finalment escull el millor modelo (el model amb el nivell d'encert més elevat). \n \nAccuracy és igual al nombre d'encerts dividit entre el nombre de documents totals. Es calcula a partir de la matriu de confusió, en el cas de la funció knn() seria: \n\naccuracy = ((825+470) / (825+470+15+20)) = 0.9737",
    "a10": {
        "p": "Apliquem la funció train(). Li passem la matriu de freqüències d'entrenament ('pila.nl[entrena.idx, ]') i les temàtiques dels documents d'entrenament ('tema[entrena.idx, ]'). Per altra banda, li diem que apliqui el mètode knn i que ho faci amb k entre 1 i 3.",
        "c": "#Funció train paquet caret \n \ndat_train<-cbind(pila.nl[entrena.idx, ], tema[entrena.idx]) \nknnGrid <-  expand.grid(k = c(1:3)) \nknn.caret <- train(`tema[entrena.idx]`~., data=dat_train, method = 'knn', tuneGrid = knnGrid)"
    },
    "i14": "Visualitzem 'knn.caret'. Observem que s'ha escollit k=1 a partir del nivell d'accuracy. \n \nknn.caret",
    "a11": {
        "p": "Realitzem la validació de la funció train() del paquet caret. Li passem les dades de proves ('test.idx').",
        "c": "#Validació train- caret \n \ndat_test<-cbind(pila.nl[test.idx, ], tema[test.idx]) \npreds_knn<-predict(knn.caret, dat_test)"
    },
    "i15": "Podem observar com la matriu de confusió del paquet caret ens aporta molta més informació. A part de la matriu de confusió en sí, apareixen diversos valors estadístics. En el cas de la funció knn() hem hagut de calcular sensitivity, specificity i accuracy 'a mà'. No comentarem tots aquests valors un per un, però tots ells es calculen a partir de la matriu de confusió. Els resultats són molt semblants als de la funció knn() (al final en els dos casos hem acabat aplicant k=1), però en aquest cas amb 4 encerts més (35 errors amb la funció knn(), 31 errors amb la funció train()). \n \nconfusionMatrix(preds_knn, as.factor(dat_test$`tema[test.idx]`))",
    "p6": "En aquest punt ja hem finalitzat el procés, disposem de 2 models entrenats per classificar documents segons pertanyen a la temàtica 'acq' o 'earn', i els models tenen un nivell d'encert considerable (entre el 97% i el 98%).\n \n Si el que volem és predir una nova dada (externa al nostre joc de dades), haurem d'analitzar aquest document (o documents) per tal d'obtenir les corresponents freqüències de termes i crear una matriu en què les files siguin els documents i les columnes els termes: dat_new. Finalment, utilitzar la funció preds_knn amb la nova matriu: preds_knn<-predict(knn.caret, dat_new).\n \n Els nostres models simplement classifiquen documents entre dues temàtiques, però en aquest àmbit de coneixement es basen els sistemes de classificació documental, de cerca de continguts i els sistemes de recomanació entre altres."
}